{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import regex\n",
    "from pathlib import Path\n",
    "from os import path, listdir, mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_hidden_columns(initial_df):\n",
    "    \"\"\"\n",
    "    Drops the hidden and empty columns from a Quant Excel Results tab DataFrame.\n",
    "    \"\"\"\n",
    "    results_df = initial_df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "    undesired_columns = [i for i in range(5, 77) if ((i + 4) % 3 != 0)]\n",
    "    for i in undesired_columns:\n",
    "        results_df.drop([f\"Unnamed: {i}\"], axis=1, inplace=True)\n",
    "    return results_df\n",
    "\n",
    "def split_plate_into_rows(results_df):\n",
    "    \"\"\"\n",
    "    Splits a given DataFrame from a Quant Excel Results tab into 16 equivalent DataFrames, one for each plate row.\n",
    "    \"\"\"\n",
    "    row_a_df = results_df.loc[0:6]\n",
    "    row_b_df = results_df.loc[7:13]\n",
    "    row_c_df = results_df.loc[14:20]\n",
    "    row_d_df = results_df.loc[21:27]\n",
    "    row_e_df = results_df.loc[28:34]\n",
    "    row_f_df = results_df.loc[35:41]\n",
    "    row_g_df = results_df.loc[42:48]\n",
    "    row_h_df = results_df.loc[49:55]\n",
    "    row_i_df = results_df.loc[56:62]\n",
    "    row_j_df = results_df.loc[63:69]\n",
    "    row_k_df = results_df.loc[70:76]\n",
    "    row_l_df = results_df.loc[77:83]\n",
    "    row_m_df = results_df.loc[84:90]\n",
    "    row_n_df = results_df.loc[91:97]\n",
    "    row_o_df = results_df.loc[98:104]\n",
    "    row_p_df = results_df.loc[105:111]\n",
    "    return [row_a_df, row_b_df, row_c_df, row_d_df, row_e_df, row_f_df, row_g_df, row_h_df, \n",
    "            row_i_df, row_j_df, row_k_df, row_l_df, row_m_df, row_n_df, row_o_df, row_p_df]\n",
    "\n",
    "\n",
    "def insert_row(row_number, df, row_value):\n",
    "    \"\"\"\n",
    "    Inserts a row into any given index of a DataFrame when provided: \n",
    "        the desired insertion index (i.e. what index the new row will have in the DataFrame), \n",
    "        the DataFrame upon which to act, \n",
    "        the values for the new row.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Starting value of upper half \n",
    "    start_upper = 0\n",
    "   \n",
    "    # End value of upper half \n",
    "    end_upper = row_number \n",
    "   \n",
    "    # Start value of lower half \n",
    "    start_lower = row_number \n",
    "   \n",
    "    # End value of lower half \n",
    "    end_lower = df.shape[0] \n",
    "   \n",
    "    # Create a list of upper_half index \n",
    "    upper_half = [*range(start_upper, end_upper, 1)] \n",
    "   \n",
    "    # Create a list of lower_half index \n",
    "    lower_half = [*range(start_lower, end_lower, 1)] \n",
    "   \n",
    "    # Increment the value of lower half by 1 \n",
    "    lower_half = [x.__add__(1) for x in lower_half] \n",
    "   \n",
    "    # Combine the two lists \n",
    "    index_ = upper_half + lower_half \n",
    "   \n",
    "    # Update the index of the dataframe \n",
    "    df.index = index_ \n",
    "   \n",
    "    # Insert a row at the end \n",
    "    df.loc[row_number] = row_value \n",
    "    \n",
    "    # Sort the index labels \n",
    "    df = df.sort_index() \n",
    "   \n",
    "    # return the dataframe \n",
    "    return df \n",
    "\n",
    "\n",
    "def new_letter_row(plate_row_letter):\n",
    "    \"\"\"\n",
    "    Creates a row of a single letter 26 columns in length when provided the letter itself.\n",
    "    \"\"\"\n",
    "    new_row = [i for i in range(0, 26)]\n",
    "    for i in range(0, 26):\n",
    "        new_row[i] = plate_row_letter\n",
    "    return new_row\n",
    "\n",
    "def transform_plate_row(row_df, plate_row_letter):\n",
    "    new_row = new_letter_row(plate_row_letter)\n",
    "    row_df = insert_row(1, row_df, new_row)\n",
    "    row_df.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "    row_df.iloc[0][0] = \"Labels\"\n",
    "    row_df.iloc[1][0] = \"ROW\"\n",
    "    row_df.iloc[7][0] = \"SOURCE WELL\"\n",
    "    headers = row_df.iloc[0]\n",
    "    row_df = row_df[1:]\n",
    "    row_df.rename(columns = headers, inplace=True)\n",
    "    new_row_labels = row_df.loc[:7, \"Labels\"]\n",
    "    row_df.rename(new_row_labels, inplace=True)\n",
    "    row_df.drop([\"Labels\"], axis=1, inplace=True)\n",
    "    row_df = row_df.transpose()\n",
    "    row_df.index.name = \"Sample ID\"\n",
    "    row_df.reset_index(inplace=True)\n",
    "    return row_df\n",
    "\n",
    "def create_binary_results(row_df):\n",
    "    \"\"\"\n",
    "    Replaces all instances of NaN for a given plate row DataFrame in the gene columns with 0, and all instances of the gene names themselves with 1. REPEAT is left untouched.\n",
    "    \"\"\"\n",
    "    row_df_filled = row_df.fillna({\"MS2\": \"NON-AMPLIFIED\", \n",
    "                                   \"N gene\": \"NON-AMPLIFIED\", \n",
    "                                   \"ORF1ab\": \"NON-AMPLIFIED\", \n",
    "                                   \"RP-Cy5\": \"NON-AMPLIFIED\", \n",
    "                                   \"S gene\": \"NON-AMPLIFIED\"})\n",
    "    row_df_binary = row_df_filled.replace({\"MS2\": \"AMPLIFIED\", \n",
    "                                           \"N gene\": \"AMPLIFIED\", \n",
    "                                           \"ORF1ab\": \"AMPLIFIED\", \n",
    "                                           \"RP-Cy5\": \"AMPLIFIED\", \n",
    "                                           \"S gene\": \"AMPLIFIED\"})\n",
    "    return row_df_binary\n",
    "\n",
    "def add_well_number(joined_df):\n",
    "    \"\"\"\n",
    "    Adds the Well Number column to a rejoined and transformed Results tab DataFrame.\n",
    "    \"\"\"\n",
    "    well_number_df = joined_df.reset_index(drop=True)\n",
    "    well_number_df.index.name = \"well\"\n",
    "    well_number_df.reset_index(inplace=True)\n",
    "    well_number_df[\"well\"] = [i for i in range(1, 385)]\n",
    "    return well_number_df\n",
    "\n",
    "def transform_results(excel_file):\n",
    "    \"\"\"\n",
    "    Takes an auto-generated Quant 12K Excel file and transforms the Results sheet from an imitation plate grid to an easy-to-read table. \n",
    "    It returns that table as a pandas DataFrame. This function also adds the Well Number for each sample as a new column. \n",
    "    \"\"\"\n",
    "    initial_df = pd.read_excel(excel_file, sheet_name=\"Results\", skiprows=2)\n",
    "    results_df = drop_hidden_columns(initial_df)\n",
    "    initial_row_df_list = split_plate_into_rows(results_df)\n",
    "    plate_row_labels = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\"]\n",
    "    inter_row_df_list = []\n",
    "    for i in range(0, 16): \n",
    "        transformed_df = transform_plate_row(initial_row_df_list[i], plate_row_labels[i])\n",
    "        binary_df = create_binary_results(transformed_df)\n",
    "        inter_row_df_list.append(binary_df)\n",
    "    joined_df = pd.concat(inter_row_df_list)\n",
    "    final_df = add_well_number(joined_df).rename(columns={\"Sample ID\": \"sample_id\",\n",
    "                                                          \"ROW\": \"row\",\n",
    "                                                          \"SOURCE WELL\": \"source_well\", \n",
    "                                                          \"N gene\": \"n_gene_result\", \n",
    "                                                          \"S gene\": \"s_gene_result\", \n",
    "                                                          \"MS2\": \"ms2_result\", \n",
    "                                                          \"ORF1ab\": \"orf1ab_result\", \n",
    "                                                          \"RP-Cy5\": \"rp_cy5_result\"})\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "def get_quant_data_from(file):\n",
    "    lines = open(file, 'r').readlines()\n",
    "    header = 'Header'\n",
    "    data = {'Header': []}\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.replace('\\n', '')\n",
    "        if line == '':\n",
    "            continue\n",
    "\n",
    "        if regex.match(r\"\\[(\\\\.|[^]])*]\", line):\n",
    "            data[header] = '\\n'.join(data[header])\n",
    "            header = line.replace('[', '').replace(']', '')\n",
    "            data[header] = []\n",
    "            continue\n",
    "\n",
    "        data[header].append(line)\n",
    "    return data\n",
    "\n",
    "def generate_target(gene):\n",
    "    if (gene == \"ms2\"):\n",
    "        return \"MS2\"\n",
    "    elif (gene == \"n_gene\"):\n",
    "        return \"N gene\"\n",
    "    elif (gene == \"s_gene\"):\n",
    "        return \"S gene\"\n",
    "    elif (gene == \"orf1ab\"):\n",
    "        return \"ORF1ab\"\n",
    "    else:\n",
    "        return \"RP-Cy5\"\n",
    "\n",
    "def get_sample_data(txt_file):\n",
    "    data = get_quant_data_from(txt_file)['Amplification Data']\n",
    "    data_string = ''\n",
    "    for string in data:\n",
    "        data_string += string + \"\\n\"\n",
    "    df = pd.read_csv(StringIO(data_string), delimiter='\\t') \\\n",
    "        .rename(columns={'Well': 'well', 'Cycle': 'cycle', 'Target Name': 'target', 'Rn': 'rn', 'Delta Rn': 'delta_rn'})\n",
    "    df['rn'] = df['rn'].str.replace(',', '')\n",
    "    df['rn'] = df['rn'].astype(float)\n",
    "    df['delta_rn'] = df['delta_rn'].str.replace(',', '')\n",
    "    df['delta_rn'] = df['delta_rn'].astype(float)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for well in df.query(f\"target == 'MS2' and cycle == 1\")['well'].values:\n",
    "        for target in pd.unique(df.query(f\"cycle == 1\")['target']).tolist():\n",
    "            dict_target_name = target.replace('-', '_').replace(' ', '_').lower()\n",
    "\n",
    "            if well not in data:\n",
    "                data[well] = {}\n",
    "\n",
    "            target_df = df.query(f\"well == {well} and target == '{target}'\")\n",
    "            data[well][dict_target_name] = target_df['rn'].values.tolist()\n",
    "            data[well][f'{dict_target_name}_delta'] = target_df['delta_rn'].values.tolist()\n",
    "\n",
    "    return data\n",
    "\n",
    "def create_gene_df(joined_df, gene):\n",
    "    gene_df = joined_df.filter(items=[\"well\", \"sample_id\", \"well_position\", f\"{gene}\"]).rename(columns={f\"{gene}\": \"result\"})\n",
    "    return gene_df\n",
    "\n",
    "def get_sample_answers(excel_file):\n",
    "    \"\"\"\n",
    "    Gene parameter must be either 'n_gene', 's_gene', 'orf1ab', 'ms2', or 'rp-cy5'. No other options are acceptable.\n",
    "    \"\"\"\n",
    "    undesirables = \"['neg', 'PC', '', 0]\"\n",
    "    #.query(f'sample_id != {undesirables}') \\\n",
    "    \n",
    "    answers_df = transform_results(excel_file) \\\n",
    "        .filter(items=['well', 'sample_id', 'ms2_result', 'n_gene_result', 'orf1ab_result', 'rp_cy5_result', 's_gene_result']) \\\n",
    "        .query(f'sample_id != {undesirables}')\n",
    "    answers_df['sample_id'] = answers_df['sample_id'].apply(str)\n",
    "    \n",
    "    \n",
    "    samples_df = pd.read_excel(excel_file, sheet_name='QUANT DATA', skiprows=42) \\\n",
    "        .query(\"`Target Name` == 'MS2'\") \\\n",
    "        .filter(items=['Well Position', 'Sample Name']) \\\n",
    "        .rename(columns={'Sample Name': 'sample_id', 'Well Position': 'well_position'})\n",
    "    samples_df['sample_id'] = samples_df['sample_id'].apply(str)\n",
    "    samples_df = samples_df.reset_index(drop=True).query(f'sample_id != {undesirables}')\n",
    "    \n",
    "    return pd.merge(answers_df, samples_df, how='inner', on='sample_id').set_index('well').to_dict('index')    \n",
    "\n",
    "def merge_dicts(a, b, path=None):\n",
    "    \"\"\"\n",
    "    Merges b into a.\n",
    "    \"\"\"\n",
    "    if path is None: path = []\n",
    "    for key in b:\n",
    "        if key in a:\n",
    "            if isinstance(a[key], dict) and isinstance(b[key], dict):\n",
    "                merge_dicts(a[key], b[key], path + [str(key)])\n",
    "            elif a[key] == b[key]:\n",
    "                pass # same leaf value\n",
    "            else:\n",
    "                raise Exception('Conflict at %s' % '.'.join(path + [str(key)]))\n",
    "        else:\n",
    "            a[key] = b[key]\n",
    "    return a\n",
    "\n",
    "def create_ml_gene_df(df, gene):\n",
    "    \"\"\"\n",
    "    Takes the transposed dataframe created from the full plate dictionary plus the desired gene and returns a dataframe suitable for a machine learning algorithm for that gene alone.\n",
    "    Gene options are 'n_gene', 's_gene', 'ms2', 'orf1ab', or 'rp_cy5'.\n",
    "    \"\"\"\n",
    "    df_gene = df.drop([column for column in df.columns if (column != f\"{gene}_result\" and \n",
    "                                                           column != f\"{gene}_delta\" and \n",
    "                                                           column != \"sample_id\" and \n",
    "                                                           column != \"well_position\")], axis=1)\n",
    "    \n",
    "    df_gene = df_gene[f\"{gene}_delta\"].apply(pd.Series) \\\n",
    "        .merge(df_gene, left_index=True, right_index=True) \\\n",
    "        .drop([f\"{gene}_delta\"], axis=1)\n",
    "    for i in range(0, 40):\n",
    "        df_gene.rename(columns={i: f\"{gene}_delta_cycle{i+1}\"}, inplace=True)\n",
    "    \n",
    "    df_gene.index.name = 'well'\n",
    "    return df_gene\n",
    "\n",
    "def get_gene_dfs(excel_file, txt_file):\n",
    "    \"\"\"\n",
    "    Given a Quant Excel file and txt file, returns a group of gene specific dataframes that can be used in a machine learning algorithm\n",
    "    \"\"\"\n",
    "    data = get_sample_data(txt_file)\n",
    "    answers = get_sample_answers(excel_file)\n",
    "    merged = merge_dicts(answers, data)\n",
    "    df = pd.DataFrame.from_dict(merged)\n",
    "    df = df.transpose()\n",
    "    gene_list = [\"n_gene\", \"s_gene\", \"orf1ab\", \"ms2\", \"rp_cy5\"]\n",
    "    gene_df_dict = {}\n",
    "    for gene in gene_list:\n",
    "        gene_df = create_ml_gene_df(df, gene)\n",
    "        gene_df_dict[f\"{gene}\"] = gene_df\n",
    "    \n",
    "    n_gene = gene_df_dict['n_gene']\n",
    "    s_gene = gene_df_dict['s_gene']\n",
    "    ms2 = gene_df_dict['ms2']\n",
    "    orf1ab = gene_df_dict['orf1ab']\n",
    "    rp_cy5 = gene_df_dict['rp_cy5']\n",
    "    return n_gene, s_gene, ms2, orf1ab, rp_cy5\n",
    "\n",
    "def make_gene_csv(gene_df, gene, plate_id):\n",
    "    gene_df['plate_id'] = plate_id\n",
    "    gene_df.to_csv(f\"{gene}.csv\")\n",
    "    \n",
    "def add_to_csv(csv_file, gene_df, plate_id):\n",
    "    gene_df['plate_id'] = plate_id\n",
    "    gene_df.to_csv(csv_file, header=None, mode='a')\n",
    "    \n",
    "    \n",
    "def check_plate_matches(excel_directory, txt_directory):\n",
    "    # Check each Excel for a matching txt file\n",
    "    for file in listdir(excel_directory):\n",
    "        plate_name = file.split('.')[0]\n",
    "        match_tracker = {\"Non-matches\": 0, \"Matches\": 0}\n",
    "        for txt_file in listdir(txt_directory):\n",
    "            txt_plate_name = txt_file.split('.')[0]\n",
    "            if (plate_name in txt_plate_name):\n",
    "                match_tracker[\"Matches\"] += 1\n",
    "            else:\n",
    "                match_tracker[\"Non-matches\"] += 1\n",
    "        if (match_tracker[\"Matches\"] != 1):\n",
    "            print(f\"The Excel file with the plate ID {plate_name} has {match_tracker['Matches']} txt matches\")\n",
    "    \n",
    "    # Check each txt file for a matching Excel file\n",
    "    for file in listdir(txt_directory):\n",
    "        plate_name = file.split('.')[0]\n",
    "        match_tracker = {\"Non-matches\": 0, \"Matches\": 0}\n",
    "        for excel_file in listdir(excel_directory):\n",
    "            excel_plate_name = excel_file.split('.')[0]\n",
    "            if (excel_plate_name in plate_name):\n",
    "                match_tracker[\"Matches\"] += 1\n",
    "            else:\n",
    "                match_tracker[\"Non-matches\"] += 1\n",
    "        if (match_tracker[\"Matches\"] != 1):\n",
    "            print(f\"The txt file with the plate ID {plate_name} has {match_tracker['Matches']} Excel matches\")\n",
    "    print(\"Completed Checking\")\n",
    "    \n",
    "def add_all_data_to_csv(excel_directory, txt_directory):\n",
    "    gene_list = ['n_gene', 's_gene', 'ms2', 'orf1ab', 'rp_cy5']\n",
    "    for excel_file in [f for f in listdir(excel_directory) if regex.match('\\\\d{6}-COV\\\\d{1,2}-[A-Z].xlsx', f)]:\n",
    "        plate_name = excel_file.split('.')[0]\n",
    "        txt_file = [f for f in listdir(txt_directory) if regex.match(f'{plate_name}_QuantStudio 12K Flex_export.txt', f)][0]\n",
    "        n_gene, s_gene, ms2, orf1ab, rp_cy5 = get_gene_dfs(path.join(excel_directory, excel_file), path.join(txt_directory, txt_file))\n",
    "        gene_df_list = [n_gene, s_gene, ms2, orf1ab, rp_cy5]\n",
    "        for gene, gene_df in zip(gene_list, gene_df_list):\n",
    "            add_to_csv(f\"{gene}.csv\", gene_df, plate_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gene, s_gene, ms2, orf1ab, rp_cy5 = get_gene_dfs(\"090120-COV1-P.xlsx\", \"090120-COV1-P_QuantStudio 12K Flex_export.txt\")\n",
    "gene_list = [n_gene, s_gene, ms2, orf1ab, rp_cy5]\n",
    "genes = [\"n_gene\", \"s_gene\", \"ms2\", \"orf1ab\", \"rp_cy5\"]\n",
    "for gene_df, gene in zip(gene_list, genes):\n",
    "    make_gene_csv(gene_df, gene, \"090120-COV1-P\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_directory = \"[txt_directory path]\"\n",
    "excel_directory = \"[excel_directory path]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_all_data_to_csv(excel_directory, txt_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
